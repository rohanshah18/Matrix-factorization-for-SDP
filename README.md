This repository contains in-class writing sample for graduate level machine learning course at the Pennsylvania State University.

Abstract:
To understand how non-convex reformulation of rank constrained convex positive semi-definite (PSD) matrix can be efficiently solved using matrix factorization as a proxy and investigate the non-linear programming algorithm to solve SDP which is practically efficient (i.e. less memory and time intensive). Secondly, to understand the non-convex geometry of low-rank matrix optimization and how converging to any local minima will approximately yield the global minimum or a strict saddle point (where the hessian matrix has a strictly negative eigenvalue).
